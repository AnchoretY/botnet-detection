{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botdet.data.dataset_botnet import BotnetDataset\n",
    "from botdet.data.dataloader import GraphDataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据含义\n",
    "batch 表示图的区分，属于哪个图中的数据\n",
    "edge_index 表示边关系\n",
    "x 表示节点,全部为1\n",
    "y 表示标签\n",
    "edge_y ？？？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "botnet_dataset_train = BotnetDataset(name='chord', split='train', graph_format='pyg')\n",
    "botnet_dataset_val = BotnetDataset(name='chord', split='val', graph_format='pyg')\n",
    "botnet_dataset_test = BotnetDataset(name='chord', split='test', graph_format='pyg')\n",
    "\n",
    "train_loader = GraphDataLoader(botnet_dataset_train, batch_size=2, shuffle=False, num_workers=0)\n",
    "val_loader = GraphDataLoader(botnet_dataset_val, batch_size=1, shuffle=False, num_workers=0)\n",
    "test_loader = GraphDataLoader(botnet_dataset_test, batch_size=1, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 图神经网络构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'chord'     # 僵尸网络的拓扑名称，['chord', 'debru', 'kadem', 'leet', 'c2', 'p2p']\n",
    "batch_size = 2\n",
    "in_memory = True\n",
    "shuffle = False\n",
    "data_dir = './data/botnet'\n",
    "\n",
    "\n",
    "device = 0\n",
    "devid = 0   # 使用的CPU编号\n",
    "seed = 0    # 随机种子\n",
    "\n",
    "\n",
    "in_channels = 1   # 输入节点特征数量\n",
    "enc_sizes = [32] * 10        # 编码层的特征维数\n",
    "\n",
    "\n",
    "num_classes = 2     # 分类数\n",
    "act = 'relu'        # 残差后添加的非线性激活函数，['none', 'lrelu', 'relu', 'elu']可选\n",
    "layer_act = 'none'    # 残差后前添加的非线性激活函数，['none', 'lrelu', 'relu', 'elu']可选\n",
    "residual_hop = 1    # 每层残差\n",
    "nodemodel = 'additive'  # 使用的节点种类，nodemodel = 'additive',['additive', 'mlp', 'attention']可选\n",
    "edge_gate = 'none'  # 独立的边缘网关？\n",
    "final = 'proj'      # 最后的输出层，['none', 'proj']可选\n",
    "nheads = [1]*10     # 多头注意力机制中的头数，应该是一个长度等于1或者层数\n",
    "att_act = 'lrelu'   # 多头注意力机制中的非线性激活函数，['none', 'lrelu', 'relu', 'elu'],\n",
    "att_dropout = 0     # 多头注意力机制中的dropout\n",
    "att_dir = 'in'      # 多头注意力的方向，['in', 'out']\n",
    "att_combine = 'cat' # 多头注意力向量进行合并的方式,['cat', 'add', 'mean']\n",
    "\n",
    "deg_norm = 'rw'     # 正则化方法，['none', 'sm', 'rw']\n",
    "aggr = 'add'        # 特征整合方法，['add', 'mean', 'max'],\n",
    "\n",
    "dropout = 0.0\n",
    "bias = True\n",
    "\n",
    "learning_rate = 0.005\n",
    "weight_decay = 5e-4\n",
    "num_epochs = 50\n",
    "early_stop = True\n",
    "save_dir = './saved_models'\n",
    "save_name = 'temp.pt'\n",
    "\n",
    "final_layer_config = {'att_combine': att_combine}  #最后一层配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botdet.models_pyg.gcn_model import GCNModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCNModel(\n",
       "  (gcn_net): ModuleList(\n",
       "    (0): GCNLayer(\n",
       "      (gcn): NodeModelAdditive (in_channels: 1, out_channels: 32, in_edgedim: None, deg_norm: rw, edge_gate: NoneType,aggr: add | number of parameters: 64)\n",
       "      (non_linear): Identity()\n",
       "    )\n",
       "    (1): GCNLayer(\n",
       "      (gcn): NodeModelAdditive (in_channels: 32, out_channels: 32, in_edgedim: None, deg_norm: rw, edge_gate: NoneType,aggr: add | number of parameters: 1056)\n",
       "      (non_linear): Identity()\n",
       "    )\n",
       "    (2): GCNLayer(\n",
       "      (gcn): NodeModelAdditive (in_channels: 32, out_channels: 32, in_edgedim: None, deg_norm: rw, edge_gate: NoneType,aggr: add | number of parameters: 1056)\n",
       "      (non_linear): Identity()\n",
       "    )\n",
       "    (3): GCNLayer(\n",
       "      (gcn): NodeModelAdditive (in_channels: 32, out_channels: 32, in_edgedim: None, deg_norm: rw, edge_gate: NoneType,aggr: add | number of parameters: 1056)\n",
       "      (non_linear): Identity()\n",
       "    )\n",
       "    (4): GCNLayer(\n",
       "      (gcn): NodeModelAdditive (in_channels: 32, out_channels: 32, in_edgedim: None, deg_norm: rw, edge_gate: NoneType,aggr: add | number of parameters: 1056)\n",
       "      (non_linear): Identity()\n",
       "    )\n",
       "    (5): GCNLayer(\n",
       "      (gcn): NodeModelAdditive (in_channels: 32, out_channels: 32, in_edgedim: None, deg_norm: rw, edge_gate: NoneType,aggr: add | number of parameters: 1056)\n",
       "      (non_linear): Identity()\n",
       "    )\n",
       "    (6): GCNLayer(\n",
       "      (gcn): NodeModelAdditive (in_channels: 32, out_channels: 32, in_edgedim: None, deg_norm: rw, edge_gate: NoneType,aggr: add | number of parameters: 1056)\n",
       "      (non_linear): Identity()\n",
       "    )\n",
       "    (7): GCNLayer(\n",
       "      (gcn): NodeModelAdditive (in_channels: 32, out_channels: 32, in_edgedim: None, deg_norm: rw, edge_gate: NoneType,aggr: add | number of parameters: 1056)\n",
       "      (non_linear): Identity()\n",
       "    )\n",
       "    (8): GCNLayer(\n",
       "      (gcn): NodeModelAdditive (in_channels: 32, out_channels: 32, in_edgedim: None, deg_norm: rw, edge_gate: NoneType,aggr: add | number of parameters: 1056)\n",
       "      (non_linear): Identity()\n",
       "    )\n",
       "    (9): GCNLayer(\n",
       "      (gcn): NodeModelAdditive (in_channels: 32, out_channels: 32, in_edgedim: None, deg_norm: rw, edge_gate: NoneType,aggr: add | number of parameters: 1056)\n",
       "      (non_linear): Identity()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (residuals): ModuleList(\n",
       "    (0): Linear(in_features=1, out_features=32, bias=False)\n",
       "    (1): Identity()\n",
       "    (2): Identity()\n",
       "    (3): Identity()\n",
       "    (4): Identity()\n",
       "    (5): Identity()\n",
       "    (6): Identity()\n",
       "    (7): Identity()\n",
       "    (8): Identity()\n",
       "    (9): Identity()\n",
       "  )\n",
       "  (non_linear): ReLU()\n",
       "  (final): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GCNModel(\n",
    "    in_channels,\n",
    "    enc_sizes,\n",
    "    num_classes,\n",
    "    non_linear=act,\n",
    "    non_linear_layer_wise=layer_act,\n",
    "    residual_hop=residual_hop,\n",
    "    dropout=dropout,\n",
    "    final_layer_config=final_layer_config,\n",
    "    final_type=final,\n",
    "    pred_on='node',\n",
    "    nodemodel=nodemodel,\n",
    "    deg_norm=deg_norm,\n",
    "    edge_gate=edge_gate,\n",
    "    aggr=aggr,\n",
    "    bias=bias,\n",
    "    nheads=nheads,\n",
    "    att_act=att_act,\n",
    "    att_dropout=att_dropout,\n",
    "    att_dir=att_dir,\n",
    "    att_combine=att_combine,\n",
    ")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import parser\n",
    "import argparse\n",
    "\n",
    "from botdet.eval.evaluation import eval_metrics, eval_predictor, PygModelPredictor\n",
    "from botdet.optim.earlystop import EarlyStopping\n",
    "\n",
    "\n",
    "def train(model, args, train_loader, val_dataset, test_dataset, optimizer, criterion,\n",
    "          scheduler=None, logger=None):\n",
    "    \"\"\"\n",
    "        model: 要进行训练的模型\n",
    "        args:\n",
    "            epochs:训练轮数\n",
    "            log_intercval: 每隔多少轮输出一条日志\n",
    "            save_dir: 存储目录\n",
    "            save_name: \n",
    "        train_loader: 训练数据加载器\n",
    "        val_ds: 验证集\n",
    "        test_ds: 测试集\n",
    "        optimizer: 优化器\n",
    "        criterion: 损失函数\n",
    "        device: GPU版本号\n",
    "        prediceter: 预测函数\n",
    "    \"\"\"\n",
    "    if logger is None:\n",
    "        logging = print\n",
    "    else:\n",
    "        logging = logger.info\n",
    "        \n",
    "    device = next(model.parameters()).device\n",
    "    predictor = PygModelPredictor(model)\n",
    "    \n",
    "    early_stopper = EarlyStopping(patience=5, mode='min', verbose=True, logger=logger)\n",
    "    \n",
    "    best_epoch = 0    # 最佳训练轮数\n",
    "    start = time.time()\n",
    "    \n",
    "    for ep in range(args.epochs):\n",
    "        loss_avg_train = 0     # 本轮训练过程中的平均loss\n",
    "        num_train_graph = 0    # 参与训练的图数量\n",
    "        model.train()\n",
    "        for n, batch in enumerate(train_loader):\n",
    "            batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x = model(batch.x, batch.edge_index)\n",
    "            loss = criterion(x, batch.y.long())\n",
    "            \n",
    "            loss_avg_train += float(loss)\n",
    "            num_train_graph += batch.num_graphs\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #-------------------打印训练效果日志--------------------------\n",
    "            if num_train_graph % args.log_interval == 0 or n == len(train_loader) - 1:\n",
    "                with torch.no_grad():\n",
    "                    # pred = x.argmax(dim=1)\n",
    "                    pred_prob = torch.softmax(x, dim=1)[:, 1]\n",
    "                    y = batch.y.long()\n",
    "                    result_dict = eval_metrics(y, pred_prob)\n",
    "                logging(f'epoch: {ep + 1}, passed number of graphs: {num_train_graph}, '\n",
    "                        f'train running loss: {loss_avg_train / num_train_graph:.5f} (passed time: {time_since(start)})')\n",
    "                logging(' ' * 10 + ', '.join(['{}: {:.5f}'.format(k, v) for k, v in result_dict.items()]))\n",
    "                \n",
    "        result_dict_avg, loss_avg = eval_predictor(val_dataset, predictor)\n",
    "        logging(f'Validation --- epoch: {ep + 1}, loss: {loss_avg:.5f}')\n",
    "        logging(' ' * 10 + ', '.join(['{}: {:.5f}'.format(k, v) for k, v in result_dict_avg.items()]))\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(loss_avg)\n",
    "\n",
    "        if args.early_stop:\n",
    "            early_stopper(loss_avg)\n",
    "        else:\n",
    "            early_stopper.improved = True\n",
    "\n",
    "        if early_stopper.improved:\n",
    "            torch.save(model, os.path.join(args.save_dir, args.save_name))\n",
    "            logging(f'model saved at {os.path.join(args.save_dir, args.save_name)}.')\n",
    "            best_epoch = ep\n",
    "        elif early_stopper.early_stop:\n",
    "            logging(f'Early stopping here.')\n",
    "            break\n",
    "        else:\n",
    "            pass   \n",
    "    #-----------------------打印最佳轮数的训练效果--------------------------   \n",
    "    if early_stopper.improved:\n",
    "        best_model = model\n",
    "    else:\n",
    "        best_model = torch.load(os.path.join(args.save_dir, args.save_name))\n",
    "    logging('*' * 12 + f' best model obtained after epoch {best_epoch + 1}, '\n",
    "                       f'saved at {os.path.join(args.save_dir, args.save_name)} ' + '*' * 12)\n",
    "    predictor = PygModelPredictor(best_model)\n",
    "    result_dict_avg, loss_avg = eval_predictor(test_dataset, predictor)\n",
    "    logging(f'Testing --- loss: {loss_avg:.5f}')\n",
    "    logging(' ' * 10 + ', '.join(['{}: {:.5f}'.format(k, v) for k, v in result_dict_avg.items()]))\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/yhk/jupyter-notebook/botnet_detect/botnet-detection'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model(batch.x, batch.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, args, train_loader, val_dataset, test_dataset, optimizer, criterion,\n",
    "          scheduler=None, logger=None):\n",
    "    if logger is None:\n",
    "        logging = print\n",
    "    else:\n",
    "        logging = logger.info\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "    predictor = PygModelPredictor(model)\n",
    "\n",
    "    early_stopper = EarlyStopping(patience=5, mode='min', verbose=True, logger=logger)\n",
    "\n",
    "    best_epoch = 0\n",
    "    start = time.time()\n",
    "    for ep in range(args.epochs):\n",
    "        loss_avg_train = 0\n",
    "        num_train_graph = 0\n",
    "        model.train()\n",
    "        for n, batch in enumerate(train_loader):\n",
    "            batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x = model(batch.x, batch.edge_index)\n",
    "            loss = criterion(x, batch.y.long())\n",
    "\n",
    "            loss_avg_train += float(loss)\n",
    "            num_train_graph += batch.num_graphs\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if num_train_graph % args.log_interval == 0 or n == len(train_loader) - 1:\n",
    "                with torch.no_grad():\n",
    "                    # pred = x.argmax(dim=1)\n",
    "                    pred_prob = torch.softmax(x, dim=1)[:, 1]\n",
    "                    y = batch.y.long()\n",
    "                    result_dict = eval_metrics(y, pred_prob)\n",
    "                logging(f'epoch: {ep + 1}, passed number of graphs: {num_train_graph}, '\n",
    "                        f'train running loss: {loss_avg_train / num_train_graph:.5f} (passed time: {time_since(start)})')\n",
    "                logging(' ' * 10 + ', '.join(['{}: {:.5f}'.format(k, v) for k, v in result_dict.items()]))\n",
    "\n",
    "        result_dict_avg, loss_avg = eval_predictor(val_dataset, predictor)\n",
    "        logging(f'Validation --- epoch: {ep + 1}, loss: {loss_avg:.5f}')\n",
    "        logging(' ' * 10 + ', '.join(['{}: {:.5f}'.format(k, v) for k, v in result_dict_avg.items()]))\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(loss_avg)\n",
    "\n",
    "        if args.early_stop:\n",
    "            early_stopper(loss_avg)\n",
    "        else:\n",
    "            early_stopper.improved = True\n",
    "\n",
    "        if early_stopper.improved:\n",
    "            torch.save(model, os.path.join(args.save_dir, args.save_name))\n",
    "            logging(f'model saved at {os.path.join(args.save_dir, args.save_name)}.')\n",
    "            best_epoch = ep\n",
    "        elif early_stopper.early_stop:\n",
    "            logging(f'Early stopping here.')\n",
    "            break\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    if early_stopper.improved:\n",
    "        best_model = model\n",
    "    else:\n",
    "        best_model = torch.load(os.path.join(args.save_dir, args.save_name))\n",
    "    logging('*' * 12 + f' best model obtained after epoch {best_epoch + 1}, '\n",
    "                       f'saved at {os.path.join(args.save_dir, args.save_name)} ' + '*' * 12)\n",
    "    predictor = PygModelPredictor(best_model)\n",
    "    result_dict_avg, loss_avg = eval_predictor(test_dataset, predictor)\n",
    "    logging(f'Testing --- loss: {loss_avg:.5f}')\n",
    "    logging(' ' * 10 + ', '.join(['{}: {:.5f}'.format(k, v) for k, v in result_dict_avg.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "row,col = batch.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     0,      0,      0,  ..., 289496, 289497, 289498],\n",
       "        [     0,      0,      0,  ..., 289496, 289497, 289498],\n",
       "        [   282,    430,    799,  ..., 289496, 289497, 289498]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = [0,0,1]\n",
    "batch.edge_index[tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.arange(24).reshape(2, 3, 4) # 初始化一个tensor，从0到23，形状为（2,3,4）\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t---> tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14, 15],\n",
      "         [16, 17, 18, 19],\n",
      "         [20, 21, 22, 23]]])\n",
      "index---> tensor([1, 1, 2])\n",
      "data1---> tensor([[[ 4,  5,  6,  7],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11]],\n",
      "\n",
      "        [[16, 17, 18, 19],\n",
      "         [16, 17, 18, 19],\n",
      "         [20, 21, 22, 23]]])\n",
      "data2---> tensor([[[ 1,  1,  2],\n",
      "         [ 5,  5,  6],\n",
      "         [ 9,  9, 10]],\n",
      "\n",
      "        [[13, 13, 14],\n",
      "         [17, 17, 18],\n",
      "         [21, 21, 22]]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.arange(24).reshape(2, 3, 4) # 初始化一个tensor，从0到23，形状为（2,3,4）\n",
    "print(\"t--->\", t)\n",
    " \n",
    "index = torch.tensor([1, 1,2]) # 要选取数据的位置\n",
    "print(\"index--->\", index)\n",
    " \n",
    "data1 = t.index_select(1, index) # 第一个参数:从第1维挑选， 第二个参数:从该维中挑选的位置\n",
    "print(\"data1--->\", data1)\n",
    " \n",
    "data2 = t.index_select(2, index) # 第一个参数:从第2维挑选， 第二个参数:从该维中挑选的位置\n",
    "print(\"data2--->\", data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.4'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_scatter.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(in_channels,num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.25, patience=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([289499, 1]) torch.Size([2, 3035520])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"Tensor\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-b179f6882269>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-84-2092d1a478ad>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-84-2092d1a478ad>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# Step 2: 对节点的特征矩阵进行线性变换\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"....\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;31m# Step 3-5: Start propagating messages.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"Tensor\") to str"
     ]
    }
   ],
   "source": [
    "loss_avg_train = 0\n",
    "num_train_graph = 0\n",
    "model.train()\n",
    "\n",
    "\n",
    "for n, batch in enumerate(train_loader):\n",
    "    batch = batch.to(device)\n",
    "    print(batch.x.shape,batch.edge_index.shape)\n",
    "    x = net(batch.x, batch.edge_index)\n",
    "    \n",
    "    \n",
    "    loss = criterion(x,batch.y.long())\n",
    "    loss_avg_train += float(loss)\n",
    "    num_train_graph += batch.num_graphs\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "#     if num_train_graph % 10 == 0 or n == len(train_loader) - 1:\n",
    "#         with torch.no_grad():\n",
    "#             # pred = x.argmax(dim=1)\n",
    "#             pred_prob = torch.softmax(x, dim=1)[:, 1]\n",
    "#             y = batch.y.long()\n",
    "#             result_dict = eval_metrics(y, pred_prob)\n",
    "#         logging(f'epoch: {ep + 1}, passed number of graphs: {num_train_graph}, '\n",
    "#                 f'train running loss: {loss_avg_train / num_train_graph:.5f} (passed time: {time_since(start)})')\n",
    "#         logging(' ' * 10 + ', '.join(['{}: {:.5f}'.format(k, v) for k, v in result_dict.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9181\n"
     ]
    }
   ],
   "source": [
    "#测试\n",
    "model.eval()\n",
    "_, pred = net(batch.x,batch.edge_index).max(dim=1)\n",
    "correct = float(pred.eq(batch.y).sum().item())\n",
    "acc = correct / batch.x.shape[0]\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "index  = torch.tensor([[2,1],[1,3],[0,2],[3,0],[3,1],[3,2]])\n",
    "src = torch.tensor([[1,2],[3,4],[5,6],[7,8],[9,10],[11,12]]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = torch.ones((4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 1],\n",
       "        [1, 3],\n",
       "        [0, 2],\n",
       "        [3, 0],\n",
       "        [3, 1],\n",
       "        [3, 2]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.],\n",
       "        [ 3.,  4.],\n",
       "        [ 5.,  6.],\n",
       "        [ 7.,  8.],\n",
       "        [ 9., 10.],\n",
       "        [11., 12.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.,  8.],\n",
       "        [ 3., 12.],\n",
       "        [ 1., 18.],\n",
       "        [27.,  4.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_scatter.scatter_add(src,index,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
